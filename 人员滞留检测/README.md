**Author:wmingzhu**

## Version1.0(2022/08)其他版本在其他项目中，本文档不记录

### 原则

在间隔时间n的两个点都检测到目标则认为是滞留，不考虑目标在这段时间内是否离开过。

### 实现方法

每个摄像头对应一个定时任务，前一个任务未完成，后一个任务不开始。每个摄像头执行相同的逻辑，互不干扰。

**detections下图片命名方法：**

camera{x}\_(origin)time{1/2}\_{n}.jpeg

x代表第x个摄像头；(origin)time{1/2}，其中time{1/2}代表时间点1或2检测到的人，origintime{1/2}代表时间点1或2检测到的人对应的完整图(即框出了目标的原frame)，最后的{n}是图片的编号。例如camera0_time1_2.jpeg代表camera0在检测点1获取到的第2个目标。

**results下的图片命名方法：**

两个时间点匹配到的图片的合并图放在这里。

**匹配逻辑：**

根据detections下的图片名称判断该次任务摄像头x是处于第几个时间点，若处于第一个时间点(即不存在camerax_time1_n.jpeg这样的图片),那么就只执行检测，然后保存检测到的人；若处于第二个时间点执行检测，然后将匹配的结果放到results目录下，之后将该摄像头两个时间点的4种图片全部删除，然后立即执行新的匹配。这样一个周期结束。

### 项目结构

![](./%E4%BA%BA%E5%91%98%E6%BB%9E%E7%95%99%E6%A3%80%E6%B5%8B.png)

​	**主要文件介绍如下:**

- **main.py**

  运行该脚本即启动程序。例：blocking_scheduler(camera_task,dt,mp,start_date=start_date(2),interval=40)，意思为从当前时刻的2秒后开始执行各个摄像头任务，每隔40秒执行一次。

- **conf**

  配置文件所在目录，定义rtsp地址或cuda信息等。如rtsp0 = rtsp://127.0.0.1:8554/video1+[[[221,91],[1321,81],[161,755],[129,727],[221,91]]]，定义rtsp地址和画面中电子围栏的区域

- **detector.py**

  用来检测人体。使用的是yolov5s模型。crop_the_person_out函数作用是把检测到的人体保存到特定文件夹下。

- **matching_the_person.py**

  用了一个MobileNet提取上面保存的人体图片的特征，然后转为向量，用于计算欧式距离，距离小于设定的阈值，则认为是同一个人。

- **procession.py**

  **do_matching函数:**

  - 加载该摄像头两个节点的图片，遍历第一个节点的图片与第二个节点的所有图片进行对比，每次返回最相似的那个图片在第二个节点所有图片中的index，第一个节点与之匹配的图片的index和这个返回的index分别追加到两个列表中，可知这两个列表的相同位置保存的是两个节点匹配图片的index，与此同时第三个列表保存两张匹配图片的距离值。
  - 筛选上面的结果。第一个节点的不同的图片可能会匹配到第二个节点同一张图片，这种情况的发生很好理解。所以这里我使用了选择了距离最小的那个作为一对couple，其他的都舍弃。
  - 从匹配的图片得到图片所在的原frame(该frame标出了该人体图)，将两个原frame垂直叠成一张作为结果返回。
  - 删除该摄像头两个节点保存的所有图片(在camera_task中会紧接着保存第一个节点的检测图片)

  **camera_task函数：**

  每个摄像头定时执行的函数。从上到下的执行逻辑为：

  - 获取一帧。如果获取失败则写入获取失败信息，然后结束此次任务

  - 如果处于第一个节点(即还不存在节点1的图片)，那么进行检测，保存检测到的图片。结束任务

  - 如果处于第二个节点，即已经存在第一个节点的图片，那么进行检测，保存检测到的第二个节点的图片，

    进行匹配(执行do_matching函数)

  - 立即获取当前帧，检测，然后保存第一个节点的图片

    

  

  

  

  

  

  

  

  

  

  
